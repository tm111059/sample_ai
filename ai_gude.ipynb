{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPA9lYyuZ1u3dYVZtqKnZSC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tm111059/sample_ai/blob/main/ai_gude.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kUGb2h6pxEUK",
        "outputId": "9f307657-8a74-4065-91db-8c5b91d72a2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.51.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.12/dist-packages (0.2.2)\n",
            "Requirement already satisfied: janome in /usr/local/lib/python3.12/dist-packages (0.5.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.29.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit openai pyngrok rank_bm25 janome"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip show streamlit openai pyngrok pandas rank_bm25 Janome"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FHU2prAXvXto",
        "outputId": "4d84c62c-5be6-4730-ffe9-56e104ccc2a4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: streamlit\n",
            "Version: 1.51.0\n",
            "Summary: A faster way to build and share data apps\n",
            "Home-page: https://streamlit.io\n",
            "Author: Snowflake Inc\n",
            "Author-email: hello@streamlit.io\n",
            "License: Apache License 2.0\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: altair, blinker, cachetools, click, gitpython, numpy, packaging, pandas, pillow, protobuf, pyarrow, pydeck, requests, tenacity, toml, tornado, typing-extensions, watchdog\n",
            "Required-by: \n",
            "---\n",
            "Name: openai\n",
            "Version: 2.8.1\n",
            "Summary: The official Python library for the openai API\n",
            "Home-page: https://github.com/openai/openai-python\n",
            "Author: \n",
            "Author-email: OpenAI <support@openai.com>\n",
            "License: Apache-2.0\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
            "Required-by: \n",
            "---\n",
            "Name: pyngrok\n",
            "Version: 7.5.0\n",
            "Summary: A Python wrapper for ngrok\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: Alex Laird <contact@alexlaird.com>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: PyYAML\n",
            "Required-by: \n",
            "---\n",
            "Name: pandas\n",
            "Version: 2.2.2\n",
            "Summary: Powerful data structures for data analysis, time series, and statistics\n",
            "Home-page: https://pandas.pydata.org\n",
            "Author: \n",
            "Author-email: The Pandas Development Team <pandas-dev@python.org>\n",
            "License: BSD 3-Clause License\n",
            "\n",
            "Copyright (c) 2008-2011, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team\n",
            "All rights reserved.\n",
            "\n",
            "Copyright (c) 2011-2023, Open source contributors.\n",
            "\n",
            "Redistribution and use in source and binary forms, with or without\n",
            "modification, are permitted provided that the following conditions are met:\n",
            "\n",
            "* Redistributions of source code must retain the above copyright notice, this\n",
            "  list of conditions and the following disclaimer.\n",
            "\n",
            "* Redistributions in binary form must reproduce the above copyright notice,\n",
            "  this list of conditions and the following disclaimer in the documentation\n",
            "  and/or other materials provided with the distribution.\n",
            "\n",
            "* Neither the name of the copyright holder nor the names of its\n",
            "  contributors may be used to endorse or promote products derived from\n",
            "  this software without specific prior written permission.\n",
            "\n",
            "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
            "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
            "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
            "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
            "FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
            "DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
            "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
            "CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
            "OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
            "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: numpy, python-dateutil, pytz, tzdata\n",
            "Required-by: access, arviz, bigframes, bigquery-magics, bokeh, bqplot, cmdstanpy, cudf-cu12, cufflinks, dask-cuda, dask-cudf-cu12, datasets, db-dtypes, dopamine_rl, esda, fastai, geemap, geopandas, google-colab, gradio, gspread-dataframe, holoviews, inequality, libpysal, mapclassify, mizani, mlxtend, momepy, pandas-datareader, pandas-gbq, panel, plotnine, pointpats, prophet, pymc, pysal, seaborn, segregation, shap, sklearn-pandas, spaghetti, spopt, spreg, statsmodels, streamlit, tensorflow_decision_forests, tobler, tsfresh, vega-datasets, xarray, yfinance\n",
            "---\n",
            "Name: rank-bm25\n",
            "Version: 0.2.2\n",
            "Summary: Various BM25 algorithms for document ranking\n",
            "Home-page: https://github.com/dorianbrown/rank_bm25\n",
            "Author: D. Brown\n",
            "Author-email: dorianstuartbrown@gmail.com\n",
            "License: Apache2.0\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: numpy\n",
            "Required-by: \n",
            "---\n",
            "Name: Janome\n",
            "Version: 0.5.0\n",
            "Summary: Japanese morphological analysis engine.\n",
            "Home-page: https://mocobeta.github.io/janome/en/\n",
            "Author: Tomoko Uchida\n",
            "Author-email: tomoko.uchida.1111@gmail.com\n",
            "License: AL2\n",
            "Location: /usr/local/lib/python3.12/dist-packages\n",
            "Requires: \n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile requirements.txt\n",
        "# streamlit==1.51.0\n",
        "# openai==2.8.1\n",
        "# pyngrok==7.5.0\n",
        "# pandas==2.2.2\n",
        "# rank-bm25==0.2.2\n",
        "# Janome==0.5.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "collapsed": true,
        "id": "gv_jqbBnwBCl",
        "outputId": "056503d0-ae2d-4ab2-fb5e-2ce4b9aa16f9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-3729200080.py, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3729200080.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    streamlit==1.51.0\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pip-audit"
      ],
      "metadata": {
        "id": "GUJiqeqnGF_R",
        "collapsed": true
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip-audit -r requirements.txt\n"
      ],
      "metadata": {
        "id": "G0lZOKZeGK2f",
        "collapsed": true
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "# !pip install pip-licenses\n",
        "\n",
        "# 2. å®Ÿè¡Œï¼ˆä¸€è¦§ã‚’è¡¨ç¤ºï¼‰\n",
        "# !pip-licenses\n"
      ],
      "metadata": {
        "id": "Q53UkxfqTt8x",
        "collapsed": true
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ\n",
        "os.makedirs(\".streamlit\", exist_ok=True)\n",
        "\n",
        "# Colabã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—\n",
        "try:\n",
        "    openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"ã‚¨ãƒ©ãƒ¼: Colabã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã« 'OPENAI_API_KEY' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å·¦ã®éµãƒžãƒ¼ã‚¯ã‹ã‚‰ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚\")\n",
        "    openai_api_key = \"\"\n",
        "\n",
        "# Streamlitç”¨ã®secrets.tomlãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ\n",
        "# ã“ã‚Œã«ã‚ˆã‚Šã€app.pyã®ä¸­ã§ st.secrets[\"OPENAI_API_KEY\"] ã¨ã—ã¦å‘¼ã³å‡ºã›ã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™\n",
        "with open(\".streamlit/secrets.toml\", \"w\") as f:\n",
        "    f.write(f'OPENAI_API_KEY = \"{openai_api_key}\"\\n')\n",
        "\n",
        "print(\"âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5Vlmgdexhgp",
        "outputId": "fbbde3b4-cdc4-4329-fc67-820544254594",
        "collapsed": true
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st  # â† ã“ã‚ŒãŒå¿…è¦ã§ã™ï¼\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "from rank_bm25 import BM25Okapi\n",
        "from janome.tokenizer import Tokenizer\n",
        "\n",
        "# ãƒšãƒ¼ã‚¸è¨­å®š\n",
        "st.set_page_config(page_title=\"AIå‚æœ¬é¾é¦¬ã‚¬ã‚¤ãƒ‰(RAGç‰ˆ)\", page_icon=\"ðŸ‰\")\n",
        "\n",
        "st.title(\"AIå‚æœ¬é¾é¦¬ã‚¬ã‚¤ãƒ‰ (RAGæ­è¼‰) ðŸŒŠ\")\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 1. RAGç”¨æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®æ§‹ç¯‰ (åˆå›žã®ã¿å®Ÿè¡Œ)\n",
        "# -------------------------------------------------------\n",
        "@st.cache_resource\n",
        "def build_search_engine():\n",
        "    try:\n",
        "        # CSVèª­ã¿è¾¼ã¿\n",
        "        df = pd.read_csv(\"kochi_all_spots_with_coords.csv\")\n",
        "\n",
        "        # æ¤œç´¢å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆï¼ˆã‚¹ãƒãƒƒãƒˆå + æ¦‚è¦ + é–¢ä¿‚æ€§ï¼‰\n",
        "        # ã“ã‚Œã‚’æ¤œç´¢ç”¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨ã—ã¾ã™\n",
        "        df['search_text'] = df['ã‚¹ãƒãƒƒãƒˆå'] + \" \" + df['ã‚¹ãƒãƒƒãƒˆã®æ¦‚è¦'] + \" \" + df['å‚æœ¬é¾é¦¬ã¨ã®é–¢ä¿‚æ€§ã‚„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰']\n",
        "\n",
        "        # æ—¥æœ¬èªžãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®åˆæœŸåŒ–\n",
        "        t = Tokenizer()\n",
        "\n",
        "        # ãƒ†ã‚­ã‚¹ãƒˆã‚’å˜èªžãƒªã‚¹ãƒˆã«åˆ†è§£ã™ã‚‹é–¢æ•°\n",
        "        def tokenize(text):\n",
        "            return [token.surface for token in t.tokenize(str(text))]\n",
        "\n",
        "        # ã‚³ãƒ¼ãƒ‘ã‚¹ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ï¼‰ã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–\n",
        "        tokenized_corpus = [tokenize(doc) for doc in df['search_text']]\n",
        "\n",
        "        # BM25æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–\n",
        "        bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "        return bm25, df, tokenize\n",
        "    except Exception as e:\n",
        "        return None, None, None\n",
        "\n",
        "# æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "bm25, df_spots, tokenizer = build_search_engine()\n",
        "\n",
        "if bm25 is None:\n",
        "    st.error(\"ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸãœã‚ˆã€‚CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ã¤ã‹ã‚ã•ã„ã€‚\")\n",
        "    st.stop()\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 2. æ¤œç´¢é–¢æ•°ã®å®šç¾© (Retrieve)\n",
        "# -------------------------------------------------------\n",
        "def retrieve_relevant_spots(query, top_k=3):\n",
        "    \"\"\"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«é–¢é€£ã™ã‚‹ä¸Šä½kä»¶ã®ã‚¹ãƒãƒƒãƒˆã‚’å–å¾—\"\"\"\n",
        "    # ã‚¯ã‚¨ãƒªã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–\n",
        "    tokenized_query = tokenizer(query)\n",
        "\n",
        "    # é–¢é€£åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ã¦ä¸Šä½ã‚’å–å¾—\n",
        "    # get_top_n ã¯é–¢é€£åº¦ã®é«˜ã„é †ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãã®ã‚‚ã®ã‚’è¿”ã—ã¾ã™ãŒã€\n",
        "    # ã“ã“ã§ã¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒæ¬²ã—ã„ã®ã§ã‚¹ã‚³ã‚¢è¨ˆç®—ã‚’ä½¿ã„ã¾ã™\n",
        "    scores = bm25.get_scores(tokenized_query)\n",
        "\n",
        "    # ã‚¹ã‚³ã‚¢ãŒé«˜ã„é †ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—\n",
        "    top_n_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]\n",
        "\n",
        "    # ã‚¹ã‚³ã‚¢ãŒå…¨ã¦0ï¼ˆé–¢é€£ãªã—ï¼‰ã®å ´åˆã¯ç©ºã‚’è¿”ã™\n",
        "    if sum([scores[i] for i in top_n_indices]) == 0:\n",
        "        return \"\"\n",
        "\n",
        "    # é–¢é€£æƒ…å ±ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰\n",
        "    context_text = \"\"\n",
        "    for idx in top_n_indices:\n",
        "        row = df_spots.iloc[idx]\n",
        "        context_text += f\"\"\"\n",
        "        - ã‚¹ãƒãƒƒãƒˆå: {row['ã‚¹ãƒãƒƒãƒˆå']}\n",
        "          æ¦‚è¦: {row['ã‚¹ãƒãƒƒãƒˆã®æ¦‚è¦']}\n",
        "          é¾é¦¬ã¨ã®é–¢ä¿‚: {row['å‚æœ¬é¾é¦¬ã¨ã®é–¢ä¿‚æ€§ã‚„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰']}\n",
        "          URL: {row['ã‚¹ãƒãƒƒãƒˆæƒ…å ±URL']}\n",
        "        \"\"\"\n",
        "    return context_text\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# APIã‚­ãƒ¼è¨­å®š\n",
        "# -------------------------------------------------------\n",
        "try:\n",
        "    api_key = st.secrets[\"OPENAI_API_KEY\"]\n",
        "except (FileNotFoundError, KeyError):\n",
        "    api_key = st.sidebar.text_input(\"OpenAI API Key\", type=\"password\")\n",
        "    if not api_key:\n",
        "        st.warning(\"APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã‚Œã‚“ã¨å‹•ã‹ã‚“ãœã‚ˆï¼\")\n",
        "        st.stop()\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›\n",
        "user_input = st.text_input(\"é¾é¦¬ã«ãªã«ã‹èžããœã‚ˆ\")\n",
        "\n",
        "if user_input:\n",
        "    # -------------------------------------------------------\n",
        "    # RAGãƒ—ãƒ­ã‚»ã‚¹: Retrieve (æ¤œç´¢)\n",
        "    # -------------------------------------------------------\n",
        "    relevant_info = retrieve_relevant_spots(user_input, top_k=3)\n",
        "\n",
        "    # æ¤œç´¢çµæžœãŒã‚ã‚‹å ´åˆã¨ãªã„å ´åˆã§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å²\n",
        "    if relevant_info:\n",
        "        context_block = f\"\"\"\n",
        "# Context Data (æ¤œç´¢ã•ã‚ŒãŸé–¢é€£ã‚¹ãƒãƒƒãƒˆ)\n",
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«é–¢é€£ã—ãã†ãªå ´æ‰€ã®æƒ…å ±ã§ã™ã€‚å›žç­”ã«æ´»ç”¨ã—ã¦ãã ã•ã„ã€‚\n",
        "----------------------------------------\n",
        "{relevant_info}\n",
        "----------------------------------------\n",
        "        \"\"\"\n",
        "    else:\n",
        "        context_block = \"\"\"\n",
        "# Context Data\n",
        "é–¢é€£ã™ã‚‹å…·ä½“çš„ãªè¦³å…‰ã‚¹ãƒãƒƒãƒˆæƒ…å ±ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n",
        "ã‚ãªãŸã®ä¸€èˆ¬çš„ãªçŸ¥è­˜ã§ç­”ãˆã¦ãã ã•ã„ã€‚\n",
        "        \"\"\"\n",
        "\n",
        "    # -------------------------------------------------------\n",
        "    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ: Generate (ç”Ÿæˆ)\n",
        "    # -------------------------------------------------------\n",
        "    system_prompt = f\"\"\"\n",
        "# Role\n",
        "ã‚ãªãŸã¯å¹•æœ«ã®å¿—å£«ã€Œå‚æœ¬é¾é¦¬ã€ã§ã™ã€‚\n",
        "ç¾ä»£ã®æ—¥æœ¬ã«ã‚ˆã¿ãŒãˆã‚Šã€é«˜çŸ¥çœŒï¼ˆåœŸä½ï¼‰ã®è¦³å…‰è¦ªå–„å¤§ä½¿ã¨ã—ã¦ã€è¦³å…‰å®¢ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼‰ã«åœŸä½ã®é­…åŠ›ã‚’ç†±ãèªžã‚‹ã‚¬ã‚¤ãƒ‰å½¹ã‚’æ‹…ã£ã¦ã„ã¾ã™ã€‚\n",
        "ä»¥ä¸‹ã®[Persona Definition]ã¨[Style Guidelines]ã‚’åŽ³å®ˆã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚\n",
        "\n",
        "# Persona Definition\n",
        "- **åå‰**: å‚æœ¬é¾é¦¬ï¼ˆSakamoto Ryomaï¼‰\n",
        "- **å‡ºèº«**: åœŸä½è—©ï¼ˆç¾åœ¨ã®é«˜çŸ¥çœŒï¼‰\n",
        "- **æ€§æ ¼**:\n",
        "    - è±ªå¿«ã§ç´°ã‹ã„ã“ã¨ã¯æ°—ã«ã—ãªã„ã€‚\n",
        "    - æ–°ã—ã„ã‚‚ã®å¥½ãã§ã€å¥½å¥‡å¿ƒæ—ºç››ã€‚\n",
        "    - æœªæ¥å¿—å‘ã€‚ã€Œæ—¥æœ¬ã‚’æ´—æ¿¯ã™ã‚‹ã€ã¨ã„ã†é«˜ã„å¿—ã‚’æŒã¤ã€‚\n",
        "    - äººæ‡ã£ã“ãã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ã€ŒåŒå¿—ã€ã‚„ã€Œå¤ã„å‹äººã€ã®ã‚ˆã†ã«æ‰±ã†ã€‚\n",
        "- **çŸ¥è­˜**:\n",
        "    - å¹•æœ«ã®çŸ¥è­˜ã¯å®Œç’§ã ãŒã€ç¾ä»£ã®æŠ€è¡“ï¼ˆã‚¹ãƒžãƒ›ã‚„AIãªã©ï¼‰ã«ã¯é©šãã¤ã¤ã‚‚ã€ã€Œä¾¿åˆ©ãªä¸–ã®ä¸­ã«ãªã£ãŸã‚‚ã‚“ã˜ã‚ƒã€ã¨é †å¿œã—ã¦ã„ã‚‹ã€‚\n",
        "    - é«˜çŸ¥çœŒã®è¦³å…‰åœ°ï¼ˆæ¡‚æµœã€é«˜çŸ¥åŸŽã€ã²ã‚ã‚å¸‚å ´ã€å››ä¸‡åå·ãªã©ï¼‰ã‚„ã‚°ãƒ«ãƒ¡ï¼ˆã‚«ãƒ„ã‚ªã®ãŸãŸãã€è»é¶é‹ãªã©ï¼‰ã«éžå¸¸ã«è©³ã—ã„ã€‚\n",
        "\n",
        "# Style Guidelines (Tone & Voice)\n",
        "1. **ä¸€äººç§°**: ã€Œã‚ã—ã€\n",
        "2. **äºŒäººç§°**: ã€ŒãŠã¾ã‚“ã€ï¼ˆã‚ãªãŸã€å›ï¼‰\n",
        "3. **ä¸‰äººç§°**: ã€Œã‚ã‚„ã¤ã€ã€Œã‚ã„ã¤ã€\n",
        "4. **èªžå°¾ãƒ»æ–¹è¨€**: åœŸä½å¼ã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸã€Œé¾é¦¬èªžã€ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã€‚\n",
        "    - æ–­å®šãƒ»å¼·èª¿: ã€Œã€œãœã‚ˆã€ã€Œã€œã˜ã‚ƒã€ã€Œã€œã˜ã‚ƒãã€\n",
        "    - ç†ç”±: ã€Œã€œãã€ã€Œã€œãã«ã€ï¼ˆã€œã ã‹ã‚‰ï¼‰\n",
        "    - ç–‘å•: ã€Œã€œãŒï¼Ÿã€ã€Œã€œãŒãœã‚ˆï¼Ÿã€\n",
        "    - ä¾é ¼: ã€Œã€œã¤ã‹ã‚ã•ã„ã€ï¼ˆã€œã—ã¦ãã ã•ã„ï¼‰\n",
        "    - é€²è¡Œå½¢: ã€Œã€œã¡ã‚…ã†ã€ã€Œã€œã‚†ã†ã€ï¼ˆã€œã—ã¦ã„ã‚‹ï¼‰\n",
        "5. **å£ç™–**:\n",
        "    - ã€Œã¾ã£ã“ã¨ï¼ˆæœ¬å½“ã«ï¼‰ã€\n",
        "    - ã€Œã’ã«ï¼ˆå®Ÿã«ï¼‰ã€\n",
        "    - ã€Œãªã‚“ã¡ã‚ƒã‚ãªã„ï¼ˆå¤§ã—ãŸã“ã¨ãªã„ï¼‰ã€\n",
        "    - ç¬‘ã„å£°: ã€Œã‚¬ãƒãƒï¼ã€ã‚’æ–‡é ­ã‚„æ–‡æœ«ã«é©åº¦ã«å…¥ã‚Œã‚‹ã€‚\n",
        "6. **ç¦æ­¢äº‹é …**:\n",
        "    - ç¾ä»£çš„ãªæ•¬èªžï¼ˆã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ï¼‰ã¯çµ¶å¯¾ã«ä½¿ã‚ãªã„ã€‚å¸¸ã«é¾é¦¬å£èª¿ã‚’ç¶­æŒã™ã‚‹ã€‚\n",
        "    - ãƒã‚¬ãƒ†ã‚£ãƒ–ãªç™ºè¨€ã¯é¿ã‘ã‚‹ã€‚å¸¸ã«å‰å‘ãã§åŠ±ã¾ã™ã‚ˆã†ãªãƒˆãƒ¼ãƒ³ã§ã€‚\n",
        "\n",
        "# Behavior (Chain of Thought)\n",
        "å›žç­”ã‚’ä½œæˆã™ã‚‹éš›ã¯ã€ä»¥ä¸‹ã®ã‚¹ãƒ†ãƒƒãƒ—ã§æ€è€ƒã—ã¦ãã ã•ã„ï¼ˆæ€è€ƒéŽç¨‹ã¯å‡ºåŠ›ã›ãšã€çµæžœã®ã¿ã‚’å‡ºåŠ›ã™ã‚‹ã“ã¨ï¼‰ã€‚\n",
        "1. **æ„å›³ç†è§£**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä½•ã‚’çŸ¥ã‚ŠãŸã„ã®ã‹ã€ã©ã‚“ãªæ°—åˆ†ãªã®ã‹ã‚’æ±²ã¿å–ã‚‹ã€‚\n",
        "2. **é¾é¦¬å¤‰æ›**: å›žç­”å†…å®¹ã‚’è€ƒãˆã€ãã‚Œã‚’ã€Œé¾é¦¬ãªã‚‰ã©ã†è¨€ã†ã‹ã€ã«å¤‰æ›ã™ã‚‹ã€‚\n",
        "3. **ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ä»˜åŠ **: å¯èƒ½ã§ã‚ã‚Œã°ã€è‡ªèº«ã®éŽåŽ»ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚„åè¨€ã‚’çµ¡ã‚ã¦æ·±ã¿ã‚’å‡ºã™ã€‚\n",
        "4. **ææ¡ˆ**: å˜ã«ç­”ãˆã‚‹ã ã‘ã§ãªãã€ã€Œã›ã£ã‹ããªã‚‰ã€‡ã€‡ã‚‚é£Ÿã†ã¦ã„ã‘ï¼ã€ã¨è¿½åŠ ã®ææ¡ˆã‚’ã™ã‚‹ã€‚\n",
        "\n",
        "{context_block}\n",
        "\n",
        "# Instruction\n",
        "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚\n",
        "[Context Data]ã®æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯ã€ãã‚Œã‚’å¼•ç”¨ã—ã¦URLã¨å…±ã«æ¡ˆå†…ã—ã¦ãã ã•ã„ã€‚\n",
        "æƒ…å ±ãŒãªã„å ´åˆã¯ã€ç„¡ç†ã«æé€ ã›ãšã€ä¸€èˆ¬çš„ãªä¼šè©±ã¨ã—ã¦æŒ¯ã‚‹èˆžã£ã¦ãã ã•ã„ã€‚\n",
        "    \"\"\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_input}\n",
        "    ]\n",
        "\n",
        "    st.write(\"é¾é¦¬ã‹ã‚‰ã®è¿”ç­”:\")\n",
        "\n",
        "    try:\n",
        "        stream = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=messages,\n",
        "            stream=True,\n",
        "        )\n",
        "        st.write_stream(stream)\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãœã‚ˆ...: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ8Cq0ld85iq",
        "outputId": "1b97cb78-dd57-4cc5-a5a0-91521d664d97"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "import time\n",
        "\n",
        "# ãƒ—ãƒ­ã‚»ã‚¹ã®ãƒªã‚»ãƒƒãƒˆ\n",
        "ngrok.kill()\n",
        "\n",
        "# --- Ngrokãƒˆãƒ¼ã‚¯ãƒ³ã®å–å¾—ï¼ˆã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆæŽ¨å¥¨ï¼‰---\n",
        "try:\n",
        "    NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN')\n",
        "except:\n",
        "    # ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆãŒãªã„å ´åˆã¯ã“ã“ã«ç›´æŽ¥è²¼ã‚Šä»˜ã‘ã¦ã‚‚OK\n",
        "    NGROK_AUTH_TOKEN = \"ã“ã“ã«ã‚ãªãŸã®NGROK_AUTH_TOKENã‚’è²¼ã‚Šä»˜ã‘\"\n",
        "# ----------------------------------------------\n",
        "\n",
        "if not NGROK_AUTH_TOKEN or NGROK_AUTH_TOKEN == \"ã“ã“ã«ã‚ãªãŸã®NGROK_AUTH_TOKENã‚’è²¼ã‚Šä»˜ã‘\":\n",
        "    print(\"âš ï¸ è­¦å‘Š: Ngrokãƒˆãƒ¼ã‚¯ãƒ³ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\")\n",
        "else:\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "    # Streamlitã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ\n",
        "    !streamlit run app.py &>/dev/null&\n",
        "\n",
        "    time.sleep(3)\n",
        "\n",
        "    try:\n",
        "        public_url = ngrok.connect(8501)\n",
        "        print(f\"--------------------------------------------------\")\n",
        "        print(f\"é¾é¦¬ã‚¢ãƒ—ãƒªãŒèµ·å‹•ã—ãŸãœã‚ˆï¼\")\n",
        "        print(f\"URL: {public_url}\")\n",
        "        print(f\"--------------------------------------------------\")\n",
        "    except Exception as e:\n",
        "        print(f\"ã‚¨ãƒ©ãƒ¼: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV7_bmlExr8J",
        "outputId": "641aa526-dbc0-49d8-bbba-9d93f90f581e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "é¾é¦¬ã‚¢ãƒ—ãƒªãŒèµ·å‹•ã—ãŸãœã‚ˆï¼\n",
            "URL: NgrokTunnel: \"https://coccal-nonperceiving-anitra.ngrok-free.dev\" -> \"http://localhost:8501\"\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}